juniorWordPairMentions <- unlist(lapply(cleanDescriptions, function(l) getWordPairCount(l, nonExperiencedWordPairs)))
seniorWordPairMentions <- unlist(lapply(cleanDescriptions, function(l) getWordPairCount(l, seniorWordPairs)))
seniorMentions <- unlist(lapply(cleanDescriptions, function(l) getWordCount(l, seniorWords)))
managingWordCount <- unlist(lapply(cleanDescriptions, function(l) getWordCount(l, "managing") + getWordCount(l, "manage")))
seniorInTitle <- unlist(lapply(jobTitles, function(l) getWordCount(l, seniorTitles)))
juniorInTitle <- unlist(lapply(jobTitles, function(l) getWordCount(l, juniorTitles)))
experienceAfterRequiredMentions <- unlist(lapply(cleanDescriptions, function(l) wordsAfterWord(l, "require", "experience")))
experienceAfterSkillMentions <- unlist(lapply(cleanDescriptions, function(l) wordsAfterWord(l, "skill", "experience")))
lookForExperience <- lapply(cleanDescriptions, wordsWithNumbers, word = "experience")
lookForYears <- unlist(lapply(lookForExperience, function(l) {
if (length(l) == 0) NA
else {
x <- sapply(l, function(el) maxNumberBeforeWords(descr = el$expr, words = c("year", "years")))
if (is.finite(max(x))) max(x) else NA
}
}))
names(lookForYears) <- NULL
lookForYears[which(lookForYears > 20)] <- NA
lookForSalary <- lapply(cleanDescriptions, wordsWithNumbers, word = "salary", distanceFromNum = 6)
names(lookForSalary) <- NULL
likelySalary <- lapply(lookForSalary, function(l) {
nNums <- sapply(l, function(l) nNumerics(l$expr))
if (length(nNums) == 0) NA
else {
if (max(nNums) > 0) {
sal <- l[which.max(nNums)[1]][[1]]$expr
paste(sal, collapse = " ")
}
else NA
}
})
likelySalary <- unlist(likelySalary)
numericSalary <- unlist(lapply(likelySalary, getSalary))
numericSalary[numericSalary > 500000] <- NA
set <- data.frame(jobTitle = jobTitles,
experienceWordCount = experienceWordCount,
experienceAfterRequiredMentions = experienceAfterRequiredMentions,
experienceAfterSkillMentions = experienceAfterSkillMentions,
juniorMentions = juniorMentions,
juniorWordPairMentions = juniorWordPairMentions,
seniorWordPairMentions = seniorWordPairMentions,
seniorMentions = seniorMentions,
managingWordCount = managingWordCount,
juniorInTitle = juniorInTitle,
reqExperienceYears = lookForYears,
offeredSalary = numericSalary)
set$infoTotalSize <- NA
for (i in 1:nrow(set)) set$infoTotalSize[i] <-
sign(set$experienceWordCount[i]) +
sign(set$experienceAfterRequiredMentions[i]) +
sign(set$experienceAfterSkillMentions[i]) -
sign(set$juniorMentions[i]) -
sign(set$juniorWordPairMentions[i]) +
sign(set$seniorWordPairMentions[i]) +
sign(set$seniorMentions[i]) +
sign(set$managingWordCount[i]) -
sign(set$juniorInTitle[i]) +
ifelse(is.na(set$reqExperienceYears[i]), 0, 1)
summary(set)
plotColumns <- names(set)[2:(length(set) - 1)]
plotColumns
sapply(names(set)[2:length(set)], function(nm) {
x <- !is.na(set[[nm]])
sum(set[[nm]][x] > 0)
})
nrow(set)
jobs <- "/home/arunas/Downloads/jobs_uk.xml"
library(xml2)
jobs2 <- read_xml(jobs)
jobs2L <- as_list(jobs2)
# install.packages("rvest")
library(rvest)
# x <- read_html(str)
cleanDescription <- function(descr) {
spl <- strsplit(descr, split = "<", fixed = TRUE)
spl2 <- unlist(lapply(spl, function(u) paste0("<", u)))
sentences <- unlist(lapply(spl2, function(x) html_text(read_html(x))))
sentences <- sentences[sentences != ""]
# sentences <- removeWords(sentences, stopwords("english"))
resentence <- tolower(unlist(strsplit(paste(sentences, collapse = " "), split = ".", fixed = TRUE)))
words <- strsplit(gsub("[[:punct:]]", " ", resentence), split = " ", fixed = TRUE)
words <- lapply(words, function(x) x[x != ""])
unlist(words)
}
descriptionSentences <- function(descr) {
spl <- strsplit(descr, split = "<", fixed = TRUE)
spl2 <- unlist(lapply(spl, function(u) paste0("<", u)))
sentences <- unlist(lapply(spl2, function(x) html_text(read_html(x))))
sentences <- sentences[sentences != ""]
# sentences <- removeWords(sentences, stopwords("english"))
resentence <- tolower(unlist(strsplit(sentences, split = ".", fixed = TRUE)))
resentence <- resentence[resentence != ""]
resentence
}
hasNumerics <- function(num) {
any(!is.na(num), na.rm = TRUE)
}
firstNumberToLastString <- function(vect) {
tmpNum <- suppressWarnings(as.numeric(vect))
if (hasNumerics(tmpNum)) {
i <- min(which(!is.na(tmpNum)))
maxNum <- max(tmpNum, na.rm = TRUE)
list(maxNum = maxNum, expr = vect)
} else {
list(maxNum = NA, expr = vect)
}
}
stringToLastNumber <- function(vect) {
tmpNum <- suppressWarnings(as.numeric(vect))
if (hasNumerics(tmpNum)) {
i <- max(which(!is.na(tmpNum)))
maxNum <- max(tmpNum, na.rm = TRUE)
list(maxNum = maxNum, expr = vect)
} else {
list(maxNum = NA, expr = vect)
}
}
maxNumberBeforeWords <- function(descr, words) {
ind <- unlist(lapply(words, function(w) which(descr == w)))
indBefore <- pmax(ind - 1, 1)
max(suppressWarnings(as.numeric(descr[indBefore])))
}
wordsWithNumbers <- function(descr, word, distanceFromNum = 5) {
# print("i:")
# print(i)
# i<-i+1
where <- grep(word, descr)
# print(where)
indicesR <- lapply(where, function(i) max(1, i - distanceFromNum):i)
indicesL <- lapply(where, function(i) i:min(length(descr), i + distanceFromNum))
wordListR <- lapply(indicesR, function(i) descr[i])
wordListL <- lapply(indicesL, function(i) descr[i])
results <- c(lapply(wordListR, firstNumberToLastString),
lapply(wordListL, stringToLastNumber))
if (length(results) > 0) {
results[sapply(results, function(l) !is.na(l$maxNum))]
} else list()
}
ngram <- function(n, words) {
if (length(words) < n) NULL
else {
if (n == 1) words
else {
len = length(words)
counter = len + 1 - n
paste(words[1:counter], ngram(n - 1, words[2:len]))
}
}
}
ngrams <- function(words, nMin = 1, nMax = 2) {
lapply(nMin:nMax, ngram, words)
}
nNumerics <- function(words) {
toNum <- suppressWarnings(as.numeric(words))
sum(!is.na(toNum))
}
getSalary <- function(salaryString) {
split <- strsplit(salaryString, split = " ", fixed = TRUE)[[1]]
numerics <- suppressWarnings(as.numeric(split))
if (is.na(numerics[1]) & !is.na(numerics[2]) & !is.na(numerics[3]) & !is.na(numerics[4]) & !is.na(numerics[5]) & (nchar(split[3]) == 3) & (nchar(split[5]) == 3)) {
salary <- ((numerics[2] * 1000) + (numerics[4] * 1000)) / 2
salary
} else if (is.na(numerics[1]) & is.na(numerics[2]) & !is.na(numerics[3]) & !is.na(numerics[4]) & !is.na(numerics[5]) & !is.na(numerics[6]) &
(nchar(split[4]) == 3) & (nchar(split[6]) == 3)) {
salary <- ((numerics[3] * 1000) + (numerics[5] * 1000)) / 2
salary
} else if (is.na(numerics[1]) & is.na(numerics[2]) & is.na(numerics[3]) & !is.na(numerics[4]) & !is.na(numerics[5]) & !is.na(numerics[6]) & !is.na(numerics[7]) &
(nchar(split[5]) == 3) & (nchar(split[7]) == 3)) {
salary <- ((numerics[4] * 1000) + (numerics[6] * 1000)) / 2
salary
} else if (is.na(numerics[1]) & !is.na(numerics[2]) & !is.na(numerics[3]) & (nchar(split[3]) == 3)) {
salary <- (numerics[2] * 1000)
salary
} else if (is.na(numerics[1]) & is.na(numerics[2]) & !is.na(numerics[3]) & !is.na(numerics[4]) & (nchar(split[4]) == 3)) {
salary <- (numerics[3] * 1000)
salary
} else if (is.na(numerics[1]) & is.na(numerics[2]) & is.na(numerics[3]) & !is.na(numerics[4]) & !is.na(numerics[5]) & (nchar(split[5]) == 3)) {
salary <- (numerics[4] * 1000)
salary
} else if (is.na(numerics[1]) & !is.na(numerics[2]) & !is.na(numerics[3]) & (nchar(split[2]) == 5 | nchar(split[2]) == 6) & (nchar(split[3]) == 5 | nchar(split[3]) == 6)) {
salary <- (numerics[2] + numerics[3]) / 2
salary
} else if (is.na(numerics[1]) & is.na(numerics[2]) & !is.na(numerics[3]) & !is.na(numerics[4]) & (nchar(split[3]) == 5 | nchar(split[3]) == 6) & (nchar(split[4]) == 5 | nchar(split[4]) == 6)) {
salary <- (numerics[3] + numerics[4]) / 2
salary
} else if (is.na(numerics[1]) & is.na(numerics[2]) & is.na(numerics[3]) & !is.na(numerics[4]) & !is.na(numerics[5]) & (nchar(split[4]) == 5 | nchar(split[4]) == 6) & (nchar(split[5]) == 5 | nchar(split[5]) == 6)) {
salary <- (numerics[4] + numerics[5]) / 2
salary
} else if (is.na(numerics[1]) & !is.na(numerics[2]) & (nchar(split[2]) == 5 | nchar(split[2]) == 6)) {
salary <- numerics[2]
salary
} else if (is.na(numerics[1]) & is.na(numerics[2]) & !is.na(numerics[3]) & (nchar(split[3]) == 5 | nchar(split[3]) == 6)) {
salary <- numerics[3]
salary
} else if (is.na(numerics[1]) & is.na(numerics[2]) & is.na(numerics[3]) & !is.na(numerics[4]) & (nchar(split[4]) == 5 | nchar(split[4]) == 6)) {
salary <- numerics[4]
salary
} else NA
}
getNearPairs <- function(indices1, indices2, distance = 5, padding = 0) {
if (length(indices1) > 0 && length(indices2) > 0) {
i <- 1
j <- 1
indiceList <- list()
while (i <= length(indices1) && j <= length(indices2)) {
if (indices1[i] <= indices2[j] && (indices2[j] - indices1[i]) <= distance) {
indiceList <- c(indiceList, list((indices1[i] - padding):(indices2[j] + padding)))
if (i < length(indices1)) { i <- i + 1 } else { j <- j + 1 }
} else if (indices2[j] < indices1[i] && (indices1[i] - indices2[j]) <= distance) {
indiceList <- c(indiceList, list((indices2[j] - padding):(indices1[i] + padding)))
if (j < length(indices2)) { j <- j + 1 } else { i <- i + 1 }
} else if (indices1[i] <= indices2[j]) {
if (i < length(indices1)) { i <- i + 1 } else { j <- j + 1 }
} else if (indices2[j] < indices1[i]) {
if (j < length(indices2)) { j <- j + 1 } else { i <- i + 1 }
}
}
indiceList
} else
{
list()
}
}
getPhrases <- function(words, word1, word2, dist = 5, pad = 3) {
g1 <- grep(word1, words)
g2 <- grep(word2, words)
indiceList <- getNearPairs(g1, g2, dist, pad)
interInd <- 1:length(words)
lapply(indiceList, function(indx) words[intersect(indx, interInd)])
}
genWordGrams <- function(words, word1, v = 2) {
g <- grep(word1, words)
g <- intersect(g, v:(length(words) - v + 1))
indices1 <- lapply(g, function(i) { (i - v + 1):i })
indices2 <- lapply(g, function(i) { i:(i + v - 1) })
indices <- unique(c(indices1, indices2))
lapply(indices, function(indx) paste(words[indx], collapse = " "))
}
getWordCount <- function(words, findWords) {
g <- unlist(lapply(findWords, function(w) grep(w, words)))
length(g)
}
getWordPairCount <- function(words, findPairs) {
g <- lapply(findPairs, function(pair) {
phr <- getPhrases(words, pair[1], pair[2], 1, 0)
length(phr)
})
sum(unlist(g))
}
wordsAfterWord <- function(words, wordBefore, wordAfter) {
g1 <- grep(wordBefore, words)
g2 <- grep(wordAfter, words)
if (length(g1) > 0 && length(g2) > 0) {
sum(g2 > min(g1))
} else 0
}
seniorWordPairs <- list(c("proven", "knowledge"), c("proven", "skill"), c("proven", "leader"), c("leader", "position"), c("manag", "team"))
seniorWords <- list(c("senior"))
seniorTitles <- list(c("senior"), c("executive"))
nonExperiencedWordPairs <- list(c("graduate", "programme"), c("entry", "level"))
nonExperiencedWords <- list(c("intern"), c("junior"))
juniorTitles <- list(c("intern"), c("junior"), c("programme"), c("temp"), c("trainee"), c("seasonal"))
entryLevelTitles <- list(c("support"), c("assistant"))
cleanDescriptions <- lapply(jobs2L, function(l) cleanDescription(l[[4]][[1]]))
cleanSentences <- lapply(jobs2L, function(l) descriptionSentences(l[[4]][[1]]))
jobTitles <- tolower(unlist(lapply(jobs2L, function(l) l[[2]][[1]])))
names(cleanDescriptions) <- NULL
names(cleanSentences) <- NULL
names(jobTitles) <- NULL
experienceWordCount <- unlist(lapply(cleanDescriptions, function(l) getWordCount(l, "experience")))
juniorMentions <- unlist(lapply(cleanDescriptions, function(l) getWordCount(l, nonExperiencedWords)))
juniorWordPairMentions <- unlist(lapply(cleanDescriptions, function(l) getWordPairCount(l, nonExperiencedWordPairs)))
seniorWordPairMentions <- unlist(lapply(cleanDescriptions, function(l) getWordPairCount(l, seniorWordPairs)))
seniorMentions <- unlist(lapply(cleanDescriptions, function(l) getWordCount(l, seniorWords)))
managingWordCount <- unlist(lapply(cleanDescriptions, function(l) getWordCount(l, "managing") + getWordCount(l, "manage")))
seniorInTitle <- unlist(lapply(jobTitles, function(l) getWordCount(l, seniorTitles)))
juniorInTitle <- unlist(lapply(jobTitles, function(l) getWordCount(l, juniorTitles)))
experienceAfterRequiredMentions <- unlist(lapply(cleanDescriptions, function(l) wordsAfterWord(l, "require", "experience")))
experienceAfterSkillMentions <- unlist(lapply(cleanDescriptions, function(l) wordsAfterWord(l, "skill", "experience")))
lookForExperience <- lapply(cleanDescriptions, wordsWithNumbers, word = "experience")
lookForYears <- unlist(lapply(lookForExperience, function(l) {
if (length(l) == 0) NA
else {
x <- sapply(l, function(el) maxNumberBeforeWords(descr = el$expr, words = c("year", "years")))
if (is.finite(max(x))) max(x) else NA
}
}))
names(lookForYears) <- NULL
lookForYears[which(lookForYears > 20)] <- NA
lookForSalary <- lapply(cleanDescriptions, wordsWithNumbers, word = "salary", distanceFromNum = 6)
names(lookForSalary) <- NULL
likelySalary <- lapply(lookForSalary, function(l) {
nNums <- sapply(l, function(l) nNumerics(l$expr))
if (length(nNums) == 0) NA
else {
if (max(nNums) > 0) {
sal <- l[which.max(nNums)[1]][[1]]$expr
paste(sal, collapse = " ")
}
else NA
}
})
likelySalary <- unlist(likelySalary)
numericSalary <- unlist(lapply(likelySalary, getSalary))
numericSalary[numericSalary > 500000] <- NA
set <- data.frame(jobTitle = jobTitles,
experienceWordCount = experienceWordCount,
experienceAfterRequiredMentions = experienceAfterRequiredMentions,
experienceAfterSkillMentions = experienceAfterSkillMentions,
juniorMentions = juniorMentions,
juniorWordPairMentions = juniorWordPairMentions,
seniorWordPairMentions = seniorWordPairMentions,
seniorMentions = seniorMentions,
managingWordCount = managingWordCount,
juniorInTitle = juniorInTitle,
reqExperienceYears = lookForYears,
offeredSalary = numericSalary)
set$infoTotalSize <- NA
for (i in 1:nrow(set)) set$infoTotalSize[i] <-
sign(set$experienceWordCount[i]) +
sign(set$experienceAfterRequiredMentions[i]) +
sign(set$experienceAfterSkillMentions[i]) -
sign(set$juniorMentions[i]) -
sign(set$juniorWordPairMentions[i]) +
sign(set$seniorWordPairMentions[i]) +
sign(set$seniorMentions[i]) +
sign(set$managingWordCount[i]) -
sign(set$juniorInTitle[i]) +
ifelse(is.na(set$reqExperienceYears[i]), 0, 1)
head(set)
cleanDescription([[3]])
cleanDescriptions[[3]]
cleanDescriptions[[5]]
head(set)
head(set, 20)
head(set[!is.na(offeredSalary), ])
head(set[!is.na(set$offeredSalary), ])
d1 = 2*(1/6)^2 +(1/3)^2
d1
d2 = 3*((1/3)-(1/8))^2 + 5*(1/8)^2
d2
d2 = 3*((1/3)-(1/10))^2 + 7*(1/10)^2
d2
d2 = 3*((1/3)-(1/8))^2 + 5*(1/8)^2
d2
collisions <- function(k, n) {
# k - inserts
# n - hash table size
k - n * (1 - ((n - 1)/n)^k)
}
collisions(5000, 10000)
collisions(5000, 20000)
collisions(5000, 30000)
collisions(5000, 50000)
install.packages("rmarkdown")
install.packages("rmarkdown")
install.packages("tinytex")
knit_with_parameters('~/HE/labour-profiles-2/pdfgen.Rmd')
?mean
?predict
?subset
df <- data.frame(a = c(1,2,3), b = (3,33,3))
df <- data.frame(a = c(1,2,3), b = c(3,33,3))
df
df[1,]
subset(df, 1)
subset(df, 1:3 == 1)
subset(df, 1:3 == 2)
subset(df, 1:3 == 3)
setwd("~/maps/workdir/city-filtering")
library(data.table)
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
canada1 <- fread("census/canada/98-310-XWE2011002-301.CSV")
colnames(canada1) <- c("geocode","name","geotype","firstnationsett2011","pop2011","pop2006","2006 adjusted population flag","Incompletely enumerated Indian reserves and Indian settlements, 2006","Population, % change","Total private dwellings, 2011","Private dwellings occupied by usual residents, 2011","Land area in square kilometres, 2011","Population density per square kilometre, 2011","National population rank, 2011","Provincial/territorial population rank, 2011")
canada1 <- canada1[, c("name", "pop2011")]
getnames <- strsplit(canada1$name, "(", fixed = TRUE)
placename <- sapply(getnames, function(x) trim(x[1]))
provname <- sapply(getnames, function(x) { gsub(")", "", x[length(x)], fixed = TRUE) })
canada1$name <- placename
canada1$state <- provname
province_codes <- c("nl", "pe", "ns", "nb", "qb", "on", "mb", "sk", "ab", "bc", "yt", "nt", "nu")
names(province_codes) <- c("N.L.", "P.E.I.", "N.S.", "N.B.", "Que.", "Ont.", "Man.", "Sask.", "Alta.", "B.C.", "Y.T.", "N.W.T.", "Nvt.")
threshold <- 20000
canada1 <- canada1[pop2011 > threshold, ]
canada1$state_code <- ""
prov_match <- match(canada1$state, names(province_codes))
canada1$state_code[!is.na(prov_match)] <- province_codes[prov_match[!is.na(prov_match)]]
counties <- grep("County", canada1$`Geographic name`)
canada1 <- canada1[!counties,]
canada2 <- fread("census/canada/pop2016wiki.csv")
canada2 <- canada2[pop2016 > threshold, ]
province_names <- c("Quebec","Ontario","British Columbia","Alberta", "Saskatchewan","Manitoba",
"Nova Scotia","New Brunswick","Nunavut","Newfoundland and Labrador","Yukon", "Prince Edward Island","Northwest Territories")
names(province_names) <- c("qb", "on", "bc", "ab", "sk", "mb", "ns", "nb", "nu", "nl", "yt", "pe", "nt")
data <- fread("../temp/tempcsvextract_ca.tsv")
data <- fread("../temp/tempcsvextract_ca.tsv")
valid_coordinates <- (data$west < data$east) & (data$south < data$north)
data <- data[valid_coordinates, ]
output_dir <- "../osmnames/city-boundary-files/ca/"
limit_cities <- 100
for (state_code in names(province_names)) {
state_name <- province_names[state_code]
state_data <- subset(data, subset = data$state == state_name)
prefilter_names <- c(canada1$name[canada1$state_code == state_code],
canada2$name[canada2$province == state_code])
altname <- sapply(state_data$alternative_names, function(x) {
split <- strsplit(x, ",", fixed = TRUE)
found <- any(split[[1]] %in% prefilter_names)
found
})
realname <- state_data$name %in% prefilter_names
namefound <- realname | altname
names(namefound) <- NULL
state_data <- subset(state_data, namefound)
filter_cities <- subset(state_data, !duplicated(state_data$name))
# filter_cities <- filter_cities[filter_cities$city != "", ]
selected_columns <- filter_cities[, c("name", "west", "south", "east", "north"), with = FALSE]
selected_columns <- head(selected_columns, limit_cities)
output <- cbind(row.names(selected_columns), selected_columns)
colnames(output)[1] <- ""
output_dir_name <- paste0(output_dir, state_code, "/")
dir.create(output_dir_name, showWarnings = TRUE)
output_file_name <- paste0(output_dir_name, state_code, "_mar2019.tsv")
write.table(output, file = output_file_name, sep = ',', row.names = FALSE, col.names = TRUE)
}
output_dir <- "../osmnames/city-boundary-files/ca/"
limit_cities <- 100
for (state_code in names(province_names)) {
state_name <- province_names[state_code]
state_data <- subset(data, subset = data$state == state_name)
prefilter_names <- c(canada1$name[canada1$state_code == state_code],
canada2$name[canada2$province == state_code])
altname <- sapply(state_data$alternative_names, function(x) {
split <- strsplit(x, ",", fixed = TRUE)
found <- any(split[[1]] %in% prefilter_names)
found
})
realname <- state_data$name %in% prefilter_names
namefound <- realname | altname
names(namefound) <- NULL
state_data <- subset(state_data, namefound)
filter_cities <- subset(state_data, !duplicated(state_data$name))
# filter_cities <- filter_cities[filter_cities$city != "", ]
selected_columns <- filter_cities[, c("name", "west", "south", "east", "north"), with = FALSE]
selected_columns <- head(selected_columns, limit_cities)
output <- cbind(row.names(selected_columns), selected_columns)
colnames(output)[1] <- ""
output_dir_name <- paste0(output_dir, state_code, "/")
dir.create(output_dir_name, showWarnings = TRUE)
output_file_name <- paste0(output_dir_name, state_code, ".tsv")
write.table(output, file = output_file_name, sep = ',', row.names = FALSE, col.names = TRUE)
}
library(data.table)
trim <- function (x) gsub("^\\s+|\\s+$", "", x)
# canada <- fread("downloads/census/canada/98-400-X2016001_English_CSV_data.csv")
# canada <- subset(canada, canada$`DIM: Age (in single years) and average age (127)` == "Total - Age")
# threshold <- 10000
# filter_canada_cities <- canada[`Dim: Sex (3): Member ID: [1]: Total - Sex` > threshold, ]
# canada <- fread("downloads/census/canada/population2016.csv")
# write.csv(canada, "downloads/census/canada/population2011.csv")
canada1 <- fread("census/canada/98-310-XWE2011002-301.CSV")
colnames(canada1) <- c("geocode","name","geotype","firstnationsett2011","pop2011","pop2006","2006 adjusted population flag","Incompletely enumerated Indian reserves and Indian settlements, 2006","Population, % change","Total private dwellings, 2011","Private dwellings occupied by usual residents, 2011","Land area in square kilometres, 2011","Population density per square kilometre, 2011","National population rank, 2011","Provincial/territorial population rank, 2011")
canada1 <- canada1[, c("name", "pop2011")]
getnames <- strsplit(canada1$name, "(", fixed = TRUE)
placename <- sapply(getnames, function(x) trim(x[1]))
provname <- sapply(getnames, function(x) { gsub(")", "", x[length(x)], fixed = TRUE) })
canada1$name <- placename
canada1$state <- provname
province_codes <- c("nl", "pe", "ns", "nb", "qb", "on", "mb", "sk", "ab", "bc", "yt", "nt", "nu")
names(province_codes) <- c("N.L.", "P.E.I.", "N.S.", "N.B.", "Que.", "Ont.", "Man.", "Sask.", "Alta.", "B.C.", "Y.T.", "N.W.T.", "Nvt.")
threshold <- 10000
canada1 <- canada1[pop2011 > threshold, ]
canada1$state_code <- ""
prov_match <- match(canada1$state, names(province_codes))
canada1$state_code[!is.na(prov_match)] <- province_codes[prov_match[!is.na(prov_match)]]
counties <- grep("County", canada1$`Geographic name`)
canada1 <- canada1[!counties,]
canada2 <- fread("census/canada/pop2016wiki.csv")
canada2 <- canada2[pop2016 > threshold, ]
province_names <- c("Quebec","Ontario","British Columbia","Alberta", "Saskatchewan","Manitoba",
"Nova Scotia","New Brunswick","Nunavut","Newfoundland and Labrador","Yukon", "Prince Edward Island","Northwest Territories")
names(province_names) <- c("qb", "on", "bc", "ab", "sk", "mb", "ns", "nb", "nu", "nl", "yt", "pe", "nt")
data <- fread("../temp/tempcsvextract_ca.tsv")
valid_coordinates <- (data$west < data$east) & (data$south < data$north)
data <- data[valid_coordinates, ]
output_dir <- "../osmnames/city-boundary-files/ca/"
limit_cities <- 100
for (state_code in names(province_names)) {
state_name <- province_names[state_code]
state_data <- subset(data, subset = data$state == state_name)
prefilter_names <- c(canada1$name[canada1$state_code == state_code],
canada2$name[canada2$province == state_code])
altname <- sapply(state_data$alternative_names, function(x) {
split <- strsplit(x, ",", fixed = TRUE)
found <- any(split[[1]] %in% prefilter_names)
found
})
realname <- state_data$name %in% prefilter_names
namefound <- realname | altname
names(namefound) <- NULL
state_data <- subset(state_data, namefound)
filter_cities <- subset(state_data, !duplicated(state_data$name))
# filter_cities <- filter_cities[filter_cities$city != "", ]
selected_columns <- filter_cities[, c("name", "west", "south", "east", "north"), with = FALSE]
selected_columns <- head(selected_columns, limit_cities)
output <- cbind(row.names(selected_columns), selected_columns)
colnames(output)[1] <- ""
output_dir_name <- paste0(output_dir, state_code, "/")
dir.create(output_dir_name, showWarnings = TRUE)
output_file_name <- paste0(output_dir_name, state_code, ".tsv")
write.table(output, file = output_file_name, sep = ',', row.names = FALSE, col.names = TRUE)
}
